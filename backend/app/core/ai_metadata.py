"""
AI ì „ìš© ë©”íƒ€ë°ì´í„° ìƒì„±ê¸° v2
- OpenAI GPT-4.5+ ì§€ì›
- Gemini 2.5+ ì§€ì›
- ìƒì„¸í•œ ë©”íƒ€ë°ì´í„° ìƒì„± (ë©”íƒ€ë°ì´í„° ì˜ˆì œ ìˆ˜ì¤€)
"""
import json
from typing import Dict, Optional
import httpx
from app.config import settings
from app.core.parser import FilenameParser
import logging
logger = logging.getLogger(__name__)



class AIMetadataGeneratorV2:
    """
    ìƒì„¸í•œ ë©”íƒ€ë°ì´í„°ë¥¼ ìƒì„±í•˜ëŠ” AI ìƒì„±ê¸°
    OpenAI GPT-4.5+, Gemini 2.5+ ì§€ì›
    """

    def __init__(self, provider: str = "openai", api_key: str = None, model: str = None):
        """
        Args:
            provider: AI ì œê³µì ('openai', 'gemini')
            api_key: API í‚¤
            model: ëª¨ë¸ëª… (ì§€ì •í•˜ì§€ ì•Šìœ¼ë©´ ìµœì‹  ëª¨ë¸ ì‚¬ìš©)
        """
        self.provider = provider.lower()

        # API í‚¤ ì„¤ì •
        if api_key:
            self.api_key = api_key
        elif self.provider == 'gemini':
            self.api_key = settings.GEMINI_API_KEY
        else:
            self.api_key = settings.OPENAI_API_KEY

        # ëª¨ë¸ ì„¤ì • (ìµœì‹  ë²„ì „ ìš°ì„ )
        if model:
            self.model = model
        elif self.provider == 'gemini':
            # Gemini 2.5 ì´ìƒ
            self.model = "gemini-2.5-flash"  # ë˜ëŠ” gemini-2.5-pro
        else:
            # OpenAI GPT-4.5 ì´ìƒ
            self.model = "gpt-4o"  # gpt-4oëŠ” GPT-4 Turbo ìµœì‹  ë²„ì „

        self.parser = FilenameParser()

    async def generate_detailed_metadata(
        self,
        filename: str,
        parent_folder: str = "",
        custom_prompt: str = None
    ) -> Dict:
        """
        ìƒì„¸í•œ ë©”íƒ€ë°ì´í„° ìƒì„±

        ë©”íƒ€ë°ì´í„° ì˜ˆì œ.md ìˆ˜ì¤€ì˜ ìƒì„¸ ì •ë³´ í¬í•¨:
        - ê¸°ë³¸ ì •ë³´ (ì œëª©, ë²„ì „, í”Œë«í¼, ê°œë°œì‚¬, ì¹´í…Œê³ ë¦¬, ë¼ì´ì„ ìŠ¤ ë“±)
        - í”„ë¡œê·¸ë¨ ì„¤ëª… (ì§§ì€ ìš”ì•½, ìƒì„¸ ì„¤ëª…)
        - ì£¼ìš” ê¸°ëŠ¥ ë¦¬ìŠ¤íŠ¸
        - ì§€ì› íŒŒì¼ í¬ë§·
        - ì‹œìŠ¤í…œ ìš”êµ¬ ì‚¬ì–‘
        - ë¦´ë¦¬ì¦ˆ ì •ë³´

        Args:
            filename: íŒŒì¼ëª…
            parent_folder: ìƒìœ„ í´ë”ëª…
            custom_prompt: ì‚¬ìš©ì ì •ì˜ í”„ë¡¬í”„íŠ¸ (Noneì´ë©´ ê¸°ë³¸ í”„ë¡¬í”„íŠ¸ ì‚¬ìš©)
        """
        # 1ë‹¨ê³„: íŒŒì¼ëª… íŒŒì‹±
        parsed = self.parser.parse(filename, parent_folder)

        # 2ë‹¨ê³„: AI ì§ˆì˜
        if self.api_key and self.api_key.strip():
            if self.provider == 'openai':
                metadata = await self._query_openai_detailed(parsed, custom_prompt)
            elif self.provider == 'gemini':
                metadata = await self._query_gemini_detailed(parsed, custom_prompt)
            else:
                logger.debug(f"Unknown provider: {self.provider}, falling back")
                metadata = self._fallback_metadata(parsed)
        else:
            metadata = self._fallback_metadata(parsed)

        return metadata

    async def _query_openai_detailed(self, parsed_info: Dict, custom_prompt: str = None) -> Dict:
        """OpenAI GPT-4.5+ APIë¡œ ìƒì„¸ ë©”íƒ€ë°ì´í„° ìƒì„±"""
        software_name = parsed_info['software_name']
        version = parsed_info.get('version', '')
        year = parsed_info.get('year', '')

        context_parts = [software_name]
        if version:
            context_parts.append(f"ë²„ì „ {version}")
        if year:
            context_parts.append(f"({year})")

        software_context = ' '.join(context_parts)

        # ì»¤ìŠ¤í…€ í”„ë¡¬í”„íŠ¸ê°€ ìˆìœ¼ë©´ ì‚¬ìš©, ì—†ìœ¼ë©´ ê¸°ë³¸ í”„ë¡¬í”„íŠ¸ ì‚¬ìš©
        if custom_prompt:
            # ì»¤ìŠ¤í…€ í”„ë¡¬í”„íŠ¸ì˜ ë³€ìˆ˜ ì¹˜í™˜ (ì†Œë¬¸ì/ëŒ€ë¬¸ì/ê´„ë”í˜• ëª¨ë‘ ì§€ì›)
            prompt = custom_prompt.replace('{software_name}', software_context)
            prompt = prompt.replace('{SOFTWARE_NAME}', software_context)
            prompt = prompt.replace('[SOFTWARE_NAME]', software_context)
        else:
            # ìƒì„¸ ë©”íƒ€ë°ì´í„° í”„ë¡¬í”„íŠ¸ (ì˜ì–´ - ë” ë‚˜ì€ ì„±ëŠ¥)
            prompt = f"""Provide detailed metadata for the software: {software_context}

Return a JSON object with the following fields. ALL fields are REQUIRED - use empty strings "" or empty arrays [] if information is unknown.

**Basic Information:**
- title: Official software name
- version: Version number (if known)
- platform: Windows, macOS, Linux, or Cross-platform
- developer: Official developer/vendor name
- category: Choose the BEST match based on PRIMARY function:
  * Graphics: Image editing, graphic design, 3D modeling
  * Media: Video/audio editing, media playback, screen recording
  * Office: Documents, spreadsheets, presentations
  * Business: Accounting, ERP, CRM, business management
  * Development: Programming, IDE, development tools
  * Utility: System utilities, optimization tools
  * Security, Network, OS, Engineering, Hardware, or Uncategorized for others
- official_website: Official website URL (full URL with https://)
- icon_url: Official logo/icon image URL (leave "" if unknown)
- license_type: Free, Freemium, Trial, Commercial, or Open Source
- language: Supported languages (e.g., "English, Korean, Japanese" or "Multilingual")

**Descriptions:**
- description_short: 50-100 character brief description (one sentence)
- description_detailed: 200-300 character detailed description (main features and purpose)

**Features (5-10 items):**
- features: Array of key features (e.g., ["Virtual machine management", "Snapshot support"])

**File Formats:**
- supported_formats: Array of supported file formats (e.g., [".vmdk", ".iso", ".ova"])

**System Requirements (object):**
- system_requirements: {{
    "os": "Operating system requirements (specific)",
    "cpu": "CPU requirements",
    "ram": "RAM requirements (minimum/recommended)",
    "disk_space": "Disk space needed",
    "gpu": "GPU requirements (if any)",
    "additional": "Additional requirements (if any)"
  }}

**Installation Info (object):**
- installation_info: {{
    "installer_type": "Installation method (e.g., EXE installer, DMG mount, Archive extraction)",
    "file_size": "Approximate file size (e.g., about 500MB)",
    "internet_required": "Internet requirement (e.g., Required for activation, Not required)"
  }}

**Release Notes:**
- release_notes: Major release notes or version history (2-3 lines if known)

**Example Output:**
{{
  "title": "VMware Workstation Pro",
  "version": "12.0.1",
  "platform": "Windows",
  "developer": "VMware, Inc.",
  "category": "Utility",
  "official_website": "https://www.vmware.com/products/workstation-pro.html",
  "icon_url": "",
  "license_type": "Commercial",
  "language": "ë‹¤êµ­ì–´ ì§€ì› (ì˜ì–´, í•œêµ­ì–´, ì¼ë³¸ì–´, ì¤‘êµ­ì–´ ë“±)",
  "description_short": "ë‹¨ì¼ PCì—ì„œ ì—¬ëŸ¬ ìš´ì˜ì²´ì œë¥¼ ê°€ìƒ ë¨¸ì‹ ìœ¼ë¡œ ì‹¤í–‰í•  ìˆ˜ ìˆëŠ” ì „ë¬¸ ê°€ìƒí™” ì†Œí”„íŠ¸ì›¨ì–´",
  "description_detailed": "VMware Workstation ProëŠ” IT ì „ë¬¸ê°€ì™€ ê°œë°œìê°€ Windows ë˜ëŠ” Linux PC í•œ ëŒ€ì—ì„œ ì—¬ëŸ¬ ìš´ì˜ì²´ì œë¥¼ ì‹¤í–‰, í…ŒìŠ¤íŠ¸, ë°°í¬í•  ìˆ˜ ìˆë„ë¡ í•˜ëŠ” ì—…ê³„ í‘œì¤€ í•˜ì´í¼ë°”ì´ì € ì†”ë£¨ì…˜ì…ë‹ˆë‹¤. ê³ ê¸‰ 3D ê·¸ë˜í”½ ì§€ì›, ê³ í•´ìƒë„ ë””ìŠ¤í”Œë ˆì´, ê°•ë ¥í•œ ê°€ìƒ ë„¤íŠ¸ì›Œí‚¹ ê¸°ëŠ¥ì„ ì œê³µí•©ë‹ˆë‹¤.",
  "features": [
    "í•˜ë‚˜ì˜ PCì—ì„œ ì—¬ëŸ¬ ìš´ì˜ì²´ì œ ë™ì‹œ ì‹¤í–‰",
    "DirectX 10 ë° OpenGL 3.3 ì§€ì›ìœ¼ë¡œ 3D ê·¸ë˜í”½ êµ¬í˜„",
    "4K UHD ë””ìŠ¤í”Œë ˆì´ ì§€ì›",
    "ê°€ìƒ ë„¤íŠ¸ì›Œí¬ êµ¬ì„± ê¸°ëŠ¥",
    "ìŠ¤ëƒ…ìƒ· ë° ë³µì œ ê¸°ëŠ¥",
    "vSphere/ESXi ì›ê²© ì—°ê²°",
    "USB 3.0 ì¥ì¹˜ ì§€ì›"
  ],
  "supported_formats": [".vmx", ".vmdk", ".ovf", ".ova", ".iso"],
  "system_requirements": {{
    "os": "Windows 7 ì´ìƒ (64ë¹„íŠ¸)",
    "cpu": "1.3GHz ì´ìƒì˜ 64ë¹„íŠ¸ Intel ë˜ëŠ” AMD ë©€í‹°ì½”ì–´ í”„ë¡œì„¸ì„œ",
    "ram": "ìµœì†Œ 2GB (4GB ì´ìƒ ê¶Œì¥)",
    "disk_space": "ì„¤ì¹˜ìš© 1.2GB (ê°€ìƒ ë¨¸ì‹ ìš© ì¶”ê°€ ê³µê°„ í•„ìš”)",
    "gpu": "DirectX 10 í˜¸í™˜ ê·¸ë˜í”½ ì¹´ë“œ",
    "additional": "BIOSì—ì„œ í•˜ë“œì›¨ì–´ ê°€ìƒí™”(Intel VT-x ë˜ëŠ” AMD-V) í™œì„±í™” í•„ìš”"
  }},
  "installation_info": {{
    "installer_type": "EXE ì‹¤í–‰ íŒŒì¼",
    "file_size": "ì•½ 300-600MB",
    "internet_required": "ë¼ì´ì„ ìŠ¤ ì¸ì¦ ë° ì—…ë°ì´íŠ¸ ì‹œ í•„ìš”"
  }},
  "release_notes": "ë²„ì „ 12.0.1: Windows 10 ì•ˆì •ì„± ê°œì„ , Intel Skylake í˜¸í™˜ì„± í–¥ìƒ, USB 3.0 ìˆ˜ì • ë° ë³´ì•ˆ íŒ¨ì¹˜ í¬í•¨"
}}

**CRITICAL RULES:**
1. Return ONLY valid JSON - no markdown, no comments, no explanations
2. Include ALL fields listed above - this is MANDATORY
3. Use empty strings "" or empty arrays [] for unknown information
4. Be specific and detailed - provide comprehensive information
5. For well-known software, fill in as much detail as possible

**LANGUAGE REQUIREMENT:**
- Provide ALL text content (descriptions, features, notes, etc.) in KOREAN language
- Keep technical terms and proper nouns in their original form
- Examples: "ê°€ìƒ ë¨¸ì‹  ê´€ë¦¬", "ìŠ¤ëƒ…ìƒ· ë° ë³µì œ ê¸°ëŠ¥", "Windows 10 ì•ˆì •ì„± ê°œì„ "
- Field names remain in English, but all VALUES must be in Korean"""

        try:
            async with httpx.AsyncClient(timeout=60.0) as client:
                response = await client.post(
                    "https://api.openai.com/v1/chat/completions",
                    headers={
                        "Authorization": f"Bearer {self.api_key}",
                        "Content-Type": "application/json"
                    },
                    json={
                        "model": self.model,
                        "messages": [
                            {
                                "role": "system",
                                "content": "You are an expert software analyst. You provide comprehensive, accurate metadata about software applications in JSON format. Always include ALL required fields in your response, even if you need to use empty strings or arrays for unknown information. Your responses are detailed, well-structured, and factually correct."
                            },
                            {
                                "role": "user",
                                "content": prompt
                            }
                        ],
                        "temperature": 0.2,
                        "max_tokens": 4096
                    }
                )

                if response.status_code == 200:
                    result = response.json()
                    content = result['choices'][0]['message']['content'].strip()

                    # JSON ì¶”ì¶œ ë° íŒŒì‹±
                    extracted_json = self._extract_json(content)
                    metadata = json.loads(extracted_json)

                    # AI ì›ë³¸ ì‘ë‹µ ì €ì¥ (ë””ë²„ê¹…ìš©)
                    metadata['ai_raw_response'] = content
                    metadata['ai_provider'] = 'openai'

                    logger.debug(f"âœ… OpenAI ìƒì„¸ ë©”íƒ€ë°ì´í„° ìƒì„± ì™„ë£Œ: {metadata.get('title')}")
                    return metadata
                else:
                    error_text = response.text
                    logger.debug(f"OpenAI API error: {response.status_code} - {error_text}")
                    return self._fallback_metadata(parsed_info)

        except json.JSONDecodeError as e:
            logger.debug(f"JSON parsing error (OpenAI): {e}")
            return self._fallback_metadata(parsed_info)
        except Exception as e:
            logger.debug(f"OpenAI API Error: {e}")
            return self._fallback_metadata(parsed_info)

    async def _query_gemini_detailed(self, parsed_info: Dict, custom_prompt: str = None) -> Dict:
        """Gemini 2.5+ APIë¡œ ìƒì„¸ ë©”íƒ€ë°ì´í„° ìƒì„±"""
        software_name = parsed_info['software_name']
        version = parsed_info.get('version', '')
        year = parsed_info.get('year', '')

        context_parts = [software_name]
        if version:
            context_parts.append(f"ë²„ì „ {version}")
        if year:
            context_parts.append(f"({year})")

        software_context = ' '.join(context_parts)

        # ì»¤ìŠ¤í…€ í”„ë¡¬í”„íŠ¸ê°€ ìˆìœ¼ë©´ ì‚¬ìš©, ì—†ìœ¼ë©´ ê¸°ë³¸ í”„ë¡¬í”„íŠ¸ ì‚¬ìš©
        if custom_prompt:
            # ì»¤ìŠ¤í…€ í”„ë¡¬í”„íŠ¸ì˜ ë³€ìˆ˜ ì¹˜í™˜ (ì†Œë¬¸ì/ëŒ€ë¬¸ì/ê´„ë”í˜• ëª¨ë‘ ì§€ì›)
            prompt = custom_prompt.replace('{software_name}', software_context)
            prompt = prompt.replace('{SOFTWARE_NAME}', software_context)
            prompt = prompt.replace('[SOFTWARE_NAME]', software_context)
        else:
            # Geminiìš© ì˜ì–´ í”„ë¡¬í”„íŠ¸ (ë” ë‚˜ì€ ì„±ëŠ¥)
            prompt = f"""Provide detailed metadata for the software: {software_context}

Return a JSON object with the following fields. ALL fields are REQUIRED - use empty strings "" or empty arrays [] if information is unknown.

**Basic Information:**
- title: Official software name
- version: Version number (if known)
- platform: Windows, macOS, Linux, or Cross-platform
- developer: Official developer/vendor name
- category: Choose the BEST match based on PRIMARY function:
  * Graphics: Image editing, graphic design, 3D modeling
  * Media: Video/audio editing, media playback, screen recording
  * Office: Documents, spreadsheets, presentations
  * Business: Accounting, ERP, CRM, business management
  * Development: Programming, IDE, development tools
  * Utility: System utilities, optimization tools
  * Security, Network, OS, Engineering, Hardware, or Uncategorized for others
- official_website: Official website URL (full URL with https://)
- icon_url: Official logo/icon image URL (leave "" if unknown)
- license_type: Free, Freemium, Trial, Commercial, or Open Source
- language: Supported languages (e.g., "English, Korean, Japanese" or "Multilingual")

**Descriptions:**
- description_short: 50-100 character brief description (one sentence)
- description_detailed: 200-300 character detailed description (main features and purpose)

**Features (5-10 items):**
- features: Array of key features (e.g., ["Virtual machine management", "Snapshot support"])

**File Formats:**
- supported_formats: Array of supported file formats (e.g., [".vmdk", ".iso", ".ova"])

**System Requirements (object):**
- system_requirements: {{
    "os": "Operating system requirements (specific)",
    "cpu": "CPU requirements",
    "ram": "RAM requirements (minimum/recommended)",
    "disk_space": "Disk space needed",
    "gpu": "GPU requirements (if any)",
    "additional": "Additional requirements (if any)"
  }}

**Installation Info (object):**
- installation_info: {{
    "installer_type": "Installation method (e.g., EXE installer, DMG mount, Archive extraction)",
    "file_size": "Approximate file size (e.g., about 500MB)",
    "internet_required": "Internet requirement (e.g., Required for activation, Not required)"
  }}

**Release Notes:**
- release_notes: Major release notes or version history (2-3 lines if known)

**Example Output:**
{{
  "title": "VMware Workstation Pro",
  "version": "12.0.1",
  "platform": "Windows",
  "developer": "VMware, Inc.",
  "category": "Utility",
  "official_website": "https://www.vmware.com/products/workstation-pro.html",
  "icon_url": "",
  "license_type": "Commercial",
  "language": "ë‹¤êµ­ì–´ ì§€ì› (ì˜ì–´, í•œêµ­ì–´, ì¼ë³¸ì–´, ì¤‘êµ­ì–´ ë“±)",
  "description_short": "ë‹¨ì¼ PCì—ì„œ ì—¬ëŸ¬ ìš´ì˜ì²´ì œë¥¼ ê°€ìƒ ë¨¸ì‹ ìœ¼ë¡œ ì‹¤í–‰í•  ìˆ˜ ìˆëŠ” ì „ë¬¸ ê°€ìƒí™” ì†Œí”„íŠ¸ì›¨ì–´",
  "description_detailed": "VMware Workstation ProëŠ” IT ì „ë¬¸ê°€ì™€ ê°œë°œìê°€ Windows ë˜ëŠ” Linux PC í•œ ëŒ€ì—ì„œ ì—¬ëŸ¬ ìš´ì˜ì²´ì œë¥¼ ì‹¤í–‰, í…ŒìŠ¤íŠ¸, ë°°í¬í•  ìˆ˜ ìˆë„ë¡ í•˜ëŠ” ì—…ê³„ í‘œì¤€ í•˜ì´í¼ë°”ì´ì € ì†”ë£¨ì…˜ì…ë‹ˆë‹¤. ê³ ê¸‰ 3D ê·¸ë˜í”½ ì§€ì›, ê³ í•´ìƒë„ ë””ìŠ¤í”Œë ˆì´, ê°•ë ¥í•œ ê°€ìƒ ë„¤íŠ¸ì›Œí‚¹ ê¸°ëŠ¥ì„ ì œê³µí•©ë‹ˆë‹¤.",
  "features": [
    "í•˜ë‚˜ì˜ PCì—ì„œ ì—¬ëŸ¬ ìš´ì˜ì²´ì œ ë™ì‹œ ì‹¤í–‰",
    "DirectX 10 ë° OpenGL 3.3 ì§€ì›ìœ¼ë¡œ 3D ê·¸ë˜í”½ êµ¬í˜„",
    "4K UHD ë””ìŠ¤í”Œë ˆì´ ì§€ì›",
    "ê°€ìƒ ë„¤íŠ¸ì›Œí¬ êµ¬ì„± ê¸°ëŠ¥",
    "ìŠ¤ëƒ…ìƒ· ë° ë³µì œ ê¸°ëŠ¥",
    "vSphere/ESXi ì›ê²© ì—°ê²°",
    "USB 3.0 ì¥ì¹˜ ì§€ì›"
  ],
  "supported_formats": [".vmx", ".vmdk", ".ovf", ".ova", ".iso"],
  "system_requirements": {{
    "os": "Windows 7 ì´ìƒ (64ë¹„íŠ¸)",
    "cpu": "1.3GHz ì´ìƒì˜ 64ë¹„íŠ¸ Intel ë˜ëŠ” AMD ë©€í‹°ì½”ì–´ í”„ë¡œì„¸ì„œ",
    "ram": "ìµœì†Œ 2GB (4GB ì´ìƒ ê¶Œì¥)",
    "disk_space": "ì„¤ì¹˜ìš© 1.2GB (ê°€ìƒ ë¨¸ì‹ ìš© ì¶”ê°€ ê³µê°„ í•„ìš”)",
    "gpu": "DirectX 10 í˜¸í™˜ ê·¸ë˜í”½ ì¹´ë“œ",
    "additional": "BIOSì—ì„œ í•˜ë“œì›¨ì–´ ê°€ìƒí™”(Intel VT-x ë˜ëŠ” AMD-V) í™œì„±í™” í•„ìš”"
  }},
  "installation_info": {{
    "installer_type": "EXE ì‹¤í–‰ íŒŒì¼",
    "file_size": "ì•½ 300-600MB",
    "internet_required": "ë¼ì´ì„ ìŠ¤ ì¸ì¦ ë° ì—…ë°ì´íŠ¸ ì‹œ í•„ìš”"
  }},
  "release_notes": "ë²„ì „ 12.0.1: Windows 10 ì•ˆì •ì„± ê°œì„ , Intel Skylake í˜¸í™˜ì„± í–¥ìƒ, USB 3.0 ìˆ˜ì • ë° ë³´ì•ˆ íŒ¨ì¹˜ í¬í•¨"
}}

**CRITICAL RULES:**
1. Return ONLY valid JSON - no markdown, no comments, no explanations
2. Include ALL fields listed above - this is MANDATORY
3. Use empty strings "" or empty arrays [] for unknown information
4. Be specific and detailed - provide comprehensive information
5. For well-known software, fill in as much detail as possible

**LANGUAGE REQUIREMENT:**
- Provide ALL text content (descriptions, features, notes, etc.) in KOREAN language
- Keep technical terms and proper nouns in their original form
- Examples: "ê°€ìƒ ë¨¸ì‹  ê´€ë¦¬", "ìŠ¤ëƒ…ìƒ· ë° ë³µì œ ê¸°ëŠ¥", "Windows 10 ì•ˆì •ì„± ê°œì„ "
- Field names remain in English, but all VALUES must be in Korean"""

        try:
            api_url = f"https://generativelanguage.googleapis.com/v1beta/models/{self.model}:generateContent?key={self.api_key}"

            # System instructionì„ ë³„ë„ë¡œ ì¶”ê°€
            system_instruction = "You are an expert software analyst. Provide comprehensive, accurate metadata about software applications in JSON format. Always include ALL required fields, even if you need to use empty strings or arrays for unknown information. Be thorough and detailed."

            async with httpx.AsyncClient(timeout=60.0) as client:
                response = await client.post(
                    api_url,
                    headers={"Content-Type": "application/json"},
                    json={
                        "system_instruction": {
                            "parts": [{"text": system_instruction}]
                        },
                        "contents": [{
                            "parts": [{"text": prompt}]
                        }],
                        "generationConfig": {
                            "temperature": 0.2,
                            "maxOutputTokens": 8192,
                            "topP": 0.95,
                            "topK": 40
                        }
                    }
                )

                if response.status_code == 200:
                    result = response.json()
                    logger.debug(f"ğŸ“¥ Gemini ì›ë³¸ ì‘ë‹µ: {result}")

                    if 'candidates' in result and len(result['candidates']) > 0:
                        content = result['candidates'][0]['content']['parts'][0]['text'].strip()
                        logger.debug(f"ğŸ“„ Gemini í…ìŠ¤íŠ¸ ì‘ë‹µ (ì²« 500ì): {content[:500]}")

                        # JSON ì¶”ì¶œ ë° íŒŒì‹±
                        extracted_json = self._extract_json(content)
                        logger.debug(f"ğŸ” ì¶”ì¶œëœ JSON (ì²« 500ì): {extracted_json[:500]}")

                        metadata = json.loads(extracted_json)

                        # AI ì›ë³¸ ì‘ë‹µ ì €ì¥ (ë””ë²„ê¹…ìš©)
                        metadata['ai_raw_response'] = content
                        metadata['ai_provider'] = 'gemini'

                        logger.debug(f"âœ… Gemini ìƒì„¸ ë©”íƒ€ë°ì´í„° ìƒì„± ì™„ë£Œ: {metadata.get('title')}")
                        return metadata
                    else:
                        logger.debug(f"âŒ Gemini API unexpected response: {result}")
                        return self._fallback_metadata(parsed_info)
                else:
                    logger.debug(f"âŒ Gemini API error: {response.status_code} - {response.text}")
                    return self._fallback_metadata(parsed_info)

        except json.JSONDecodeError as e:
            logger.debug(f"âŒ JSON parsing error (Gemini): {e}")
            logger.debug(f"   íŒŒì‹± ì‹œë„í•œ í…ìŠ¤íŠ¸: {extracted_json if 'extracted_json' in locals() else 'N/A'}")
            return self._fallback_metadata(parsed_info)
        except Exception as e:
            logger.debug(f"âŒ Gemini API Error: {e}")
            import traceback
            traceback.print_exc()
            return self._fallback_metadata(parsed_info)

    def _extract_json(self, text: str) -> str:
        """í…ìŠ¤íŠ¸ì—ì„œ JSON ì¶”ì¶œ (ë§ˆí¬ë‹¤ìš´ ì½”ë“œ ë¸”ë¡ ì œê±°)"""
        text = text.strip()
        if text.startswith('```'):
            lines = text.split('\n')
            if lines[0].startswith('```'):
                lines = lines[1:]
            if lines and lines[-1].strip() == '```':
                lines = lines[:-1]
            text = '\n'.join(lines)

        return text.strip()

    async def is_filename_clear_for_matching(
        self,
        filename: str,
        parent_folder: str = ""
    ) -> bool:
        """
        AIë¥¼ ì‚¬ìš©í•˜ì—¬ íŒŒì¼ëª…ì´ ìë™ ë§¤ì¹­ì— ì¶©ë¶„íˆ ëª…í™•í•œì§€ íŒë‹¨

        Args:
            filename: íŒŒì¼ëª…
            parent_folder: ë¶€ëª¨ í´ë”ëª…

        Returns:
            True: ëª…í™•í•œ íŒŒì¼ëª… (ìë™ AI ë§¤ì¹­ ê°€ëŠ¥)
            False: ë¶ˆëª…í™•í•œ íŒŒì¼ëª… (ê²€ìƒ‰ëœ ëª©ë¡ì— í‘œì‹œ)
        """
        # API í‚¤ê°€ ì—†ìœ¼ë©´ ê¸°ë³¸ì ìœ¼ë¡œ True ë°˜í™˜ (ê¸°ì¡´ ë™ì‘ ìœ ì§€)
        if not self.api_key or not self.api_key.strip():
            return True

        # íŒŒì¼ëª… íŒŒì‹±
        parsed = self.parser.parse(filename, parent_folder)
        software_name = parsed['software_name']
        version = parsed.get('version', '')

        # ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±
        context = f"íŒŒì¼ëª…: {filename}"
        if parent_folder:
            context += f"\ní´ë”ëª…: {parent_folder}"
        context += f"\níŒŒì‹± ê²°ê³¼: {software_name}"
        if version:
            context += f" (ë²„ì „: {version})"

        # ê°„ë‹¨í•œ í”„ë¡¬í”„íŠ¸ (Yes/No ë‹µë³€ë§Œ ìš”ì²­)
        prompt = f"""{context}

ìœ„ íŒŒì¼ëª…ì´ ì†Œí”„íŠ¸ì›¨ì–´ë¥¼ ëª…í™•í•˜ê²Œ ì‹ë³„í•  ìˆ˜ ìˆëŠ”ì§€ íŒë‹¨í•´ì£¼ì„¸ìš”.

**ëª…í™•í•œ íŒŒì¼ëª…ì˜ ì¡°ê±´:**
- ì†Œí”„íŠ¸ì›¨ì–´ì˜ ì •í™•í•œ ì´ë¦„ì„ í¬í•¨
- ì œì¡°ì‚¬ë‚˜ ë¸Œëœë“œëª…ì´ í¬í•¨ë˜ì–´ ìˆìœ¼ë©´ ë” ì¢‹ìŒ
- ë²„ì „ ì •ë³´ê°€ ìˆìœ¼ë©´ ë” ëª…í™•í•¨
- ì˜ˆ: "Adobe Photoshop 2024 v25.0.iso", "Visual Studio Code 1.85.exe"

**ë¶ˆëª…í™•í•œ íŒŒì¼ëª…ì˜ ì˜ˆ:**
- ë„ˆë¬´ ì¼ë°˜ì ì¸ ì´ë¦„: "setup.exe", "installer.zip", "patch.exe"
- ì˜ë¯¸ ì—†ëŠ” ìˆ«ì/ë¬¸ì ì¡°í•©: "abc123.exe", "tmp_file.zip"
- íŒŒì¼ëª…ë§Œìœ¼ë¡œëŠ” ì–´ë–¤ ì†Œí”„íŠ¸ì›¨ì–´ì¸ì§€ ì•Œ ìˆ˜ ì—†ëŠ” ê²½ìš°

ë‹¤ìŒ ì¤‘ í•˜ë‚˜ë¡œë§Œ ë‹µë³€í•´ì£¼ì„¸ìš”:
- CLEAR: íŒŒì¼ëª…ì´ ëª…í™•í•˜ì—¬ ìë™ AI ë§¤ì¹­ ê°€ëŠ¥
- UNCLEAR: íŒŒì¼ëª…ì´ ë¶ˆëª…í™•í•˜ì—¬ ì‚¬ìš©ì í™•ì¸ í•„ìš”

ë‹µë³€:"""

        try:
            if self.provider == 'openai':
                return await self._judge_clarity_openai(prompt)
            elif self.provider == 'gemini':
                return await self._judge_clarity_gemini(prompt)
            else:
                # ì•Œ ìˆ˜ ì—†ëŠ” ì œê³µìëŠ” ê¸°ë³¸ê°’ True
                return True
        except Exception as e:
            logger.debug(f"íŒŒì¼ëª… ëª…í™•ì„± íŒë‹¨ ì‹¤íŒ¨: {e}")
            # ì—ëŸ¬ ì‹œ ì•ˆì „í•˜ê²Œ True ë°˜í™˜ (ê¸°ì¡´ ë™ì‘ ìœ ì§€)
            return True

    async def _judge_clarity_openai(self, prompt: str) -> bool:
        """OpenAIë¡œ íŒŒì¼ëª… ëª…í™•ì„± íŒë‹¨"""
        try:
            async with httpx.AsyncClient(timeout=30.0) as client:
                response = await client.post(
                    "https://api.openai.com/v1/chat/completions",
                    headers={
                        "Authorization": f"Bearer {self.api_key}",
                        "Content-Type": "application/json"
                    },
                    json={
                        "model": self.model,
                        "messages": [
                            {
                                "role": "system",
                                "content": "You are a software filename analyzer. Answer only with CLEAR or UNCLEAR."
                            },
                            {
                                "role": "user",
                                "content": prompt
                            }
                        ],
                        "temperature": 0.1,
                        "max_tokens": 10
                    }
                )

                if response.status_code == 200:
                    result = response.json()
                    answer = result['choices'][0]['message']['content'].strip().upper()
                    is_clear = 'CLEAR' in answer
                    logger.debug(f"íŒŒì¼ëª… ëª…í™•ì„± íŒë‹¨ (OpenAI): {answer} â†’ {is_clear}")
                    return is_clear
                else:
                    logger.debug(f"OpenAI clarity check failed: {response.status_code}")
                    return True
        except Exception as e:
            logger.debug(f"OpenAI clarity check error: {e}")
            return True

    async def _judge_clarity_gemini(self, prompt: str) -> bool:
        """Geminië¡œ íŒŒì¼ëª… ëª…í™•ì„± íŒë‹¨"""
        try:
            api_url = f"https://generativelanguage.googleapis.com/v1beta/models/{self.model}:generateContent?key={self.api_key}"

            async with httpx.AsyncClient(timeout=30.0) as client:
                response = await client.post(
                    api_url,
                    headers={"Content-Type": "application/json"},
                    json={
                        "contents": [{
                            "parts": [{"text": prompt}]
                        }],
                        "generationConfig": {
                            "temperature": 0.1,
                            "maxOutputTokens": 10
                        }
                    }
                )

                if response.status_code == 200:
                    result = response.json()
                    if 'candidates' in result and len(result['candidates']) > 0:
                        answer = result['candidates'][0]['content']['parts'][0]['text'].strip().upper()
                        is_clear = 'CLEAR' in answer
                        logger.debug(f"íŒŒì¼ëª… ëª…í™•ì„± íŒë‹¨ (Gemini): {answer} â†’ {is_clear}")
                        return is_clear
                    else:
                        logger.debug(f"Gemini clarity check: unexpected response")
                        return True
                else:
                    logger.debug(f"Gemini clarity check failed: {response.status_code}")
                    return True
        except Exception as e:
            logger.debug(f"Gemini clarity check error: {e}")
            return True

    def _fallback_metadata(self, parsed_info: Dict) -> Dict:
        """AI ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ ë©”íƒ€ë°ì´í„°"""
        software_name = parsed_info['software_name']

        return {
            'title': software_name,
            'version': parsed_info.get('version', ''),
            'platform': 'Windows',
            'developer': parsed_info.get('vendor', ''),
            'category': 'Utility',
            'official_website': '',
            'license_type': '',
            'language': '',
            'description_short': f"{software_name} ì†Œí”„íŠ¸ì›¨ì–´",
            'description_detailed': '',
            'features': [],
            'supported_formats': [],
            'system_requirements': {
                'os': '',
                'cpu': '',
                'ram': '',
                'disk_space': '',
                'gpu': '',
                'additional': ''
            },
            'installation_info': {
                'installer_type': '',
                'file_size': '',
                'internet_required': ''
            },
            'release_notes': ''
        }
